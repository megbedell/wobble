{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emcee\n",
    "from tqdm import tqdm\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import starry\n",
    "from ylm_rot import get_ylm_coeffs\n",
    "print(\"Using `starry` version %s.\" % starry.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "matplotlib.rcParams['axes.formatter.useoffset'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the RV dataset generated by `wobble`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, rv, err = np.loadtxt(\"HD189733_rvs.txt\", unpack=True, skiprows=1, delimiter=',')\n",
    "idx = np.argsort(time)\n",
    "time = time[idx]\n",
    "rv = rv[idx]\n",
    "err = err[idx]\n",
    "tref = 2454279.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal(object):\n",
    "    \"\"\"A normal distribution.\"\"\"\n",
    "    def __init__(self, mean, sigma):\n",
    "        self.mean = mean\n",
    "        self.sigma = sigma\n",
    "    def sample(self):\n",
    "        return self.mean + self.sigma * np.random.randn()\n",
    "    def evaluate(self, x):\n",
    "        return -0.5 * (x - self.mean) ** 2 / self.sigma ** 2\n",
    "\n",
    "class Uniform(object):\n",
    "    \"\"\"A uniform distribution.\"\"\"\n",
    "    def __init__(self, low, high):\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "    def sample(self):\n",
    "        return np.random.uniform(self.low, self.high)\n",
    "    def evaluate(self, x):\n",
    "        if (x < self.low) or (x > self.high):\n",
    "            return -np.inf\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "class Sine(object):\n",
    "    \"\"\"\n",
    "    A sine distribution.\n",
    "    \n",
    "    This is an uninformative distribution for the \n",
    "    inclination of the stellar rotation axis.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def sample(self):\n",
    "        x = np.random.random()\n",
    "        y = np.arccos(1 - x) * 180 / np.pi\n",
    "        z = np.random.random()\n",
    "        if z < 0.5:\n",
    "            return 180 - y\n",
    "        else:\n",
    "            return y\n",
    "    def evaluate(self, x):\n",
    "        if x < 0 or x > 180:\n",
    "            return -np.inf\n",
    "        else:\n",
    "            return np.log10(np.sin(x * np.pi / 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior:\n",
    "    \"\"\"A class containing all the information on our priors.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = ['veq', 'obl', 'inc', 'alpha', 'q1', 'q2', \n",
    "                       'baseline', 'K', 'b_t0', 'b_per', \n",
    "                       'b_inc', 'b_r', 'b_a', 'ln_err']\n",
    "        \n",
    "        self.names = [r'$v_\\mathrm{eq}$',\n",
    "                      r'$\\lambda$',\n",
    "                      r'$i$',\n",
    "                      r'$\\alpha$',\n",
    "                      r'$q_1$',\n",
    "                      r'$q_2$',\n",
    "                      r'$v_\\mathrm{0}$',\n",
    "                      r'$K$',\n",
    "                      r'$t_\\mathrm{0,p}$',\n",
    "                      r'$P_\\mathrm{p}$',\n",
    "                      r'$i_\\mathrm{p}$',\n",
    "                      r'$r_\\mathrm{p}$',\n",
    "                      r'$a$',\n",
    "                      r'$\\ln\\sigma$']\n",
    "        \n",
    "        # The actual priors we use.\n",
    "        # Some of these taken from Table 1 in Cegla et al. (2016)\n",
    "        # Others are uniform / uninformative priors\n",
    "        self.veq = Uniform(0, 1e4)\n",
    "        self.obl = Uniform(-90, 90)\n",
    "        self.inc = Sine()\n",
    "        self.alpha = Uniform(-1, 1)\n",
    "        self.q1 = Uniform(0, 1)\n",
    "        self.q2 = Uniform(0, 1)\n",
    "        self.baseline = Uniform(-10000, -9900)\n",
    "        self.K = Uniform(180, 220)\n",
    "        self.b_t0 = Normal(2454279.436714, 0.000015)\n",
    "        self.b_per = Normal(2.21857567, 0.00000015)\n",
    "        self.b_inc = Normal(85.710, 0.024)\n",
    "        self.b_r = Normal(0.15667, 0.00012)\n",
    "        self.b_a = Normal(8.863, 0.020)\n",
    "        self.ln_err = Uniform(-3, 3)\n",
    "        \n",
    "        # Distributions for the initial MCMC step\n",
    "        self.veq_guess = Normal(4500, 100)\n",
    "        self.obl_guess = Normal(-0.4, 0.3)\n",
    "        self.inc_guess = Normal(100, 2.0)\n",
    "        self.alpha_guess = Uniform(-0.5, 0.5)\n",
    "        self.q1_guess = Uniform(0, 1)\n",
    "        self.q2_guess = Uniform(0, 1)\n",
    "        self.baseline_guess = Normal(-9950.0, 3.0)\n",
    "        self.K_guess = Normal(200.56, 0.88)\n",
    "        self.b_t0_guess = Normal(2454279.436714, 0.000015)\n",
    "        self.b_per_guess = Normal(2.21857567, 0.00000015)\n",
    "        self.b_inc_guess = Normal(85.710, 0.024)\n",
    "        self.b_r_guess = Normal(0.15667, 0.00012)\n",
    "        self.b_a_guess = Normal(8.863, 0.020)\n",
    "        self.ln_err_guess = Normal(0, 0.1)\n",
    "        \n",
    "    def evaluate(self, x):\n",
    "        \"\"\"Evaluate the log prior.\"\"\"\n",
    "        return np.sum([getattr(self, p).evaluate(x[i]) for i, p in enumerate(self.params)])\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Sample from the prior distribution.\"\"\"\n",
    "        return [getattr(self, p).sample() for i, p in enumerate(self.params)]\n",
    "    \n",
    "    def guess(self):\n",
    "        \"\"\"Sample from the `guess' distribution.\"\"\"\n",
    "        return [getattr(self, p + \"_guess\").sample() for i, p in enumerate(self.params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the prior\n",
    "prior = Prior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our model and likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our `starry` system\n",
    "star = starry.kepler.Primary(5)\n",
    "planet = starry.kepler.Secondary(0)\n",
    "system = starry.kepler.System(star, planet)\n",
    "map_unif = starry.Map(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(x):\n",
    "    \"\"\"Compute the RV model given a parameter vector `x`.\"\"\"\n",
    "    # Get our params\n",
    "    veq, obl, inc, alpha, q1, q2, baseline, K, b_t0, b_per, b_inc, b_r, b_a, ln_err = x\n",
    "    \n",
    "    # Planet params\n",
    "    planet.tref = b_t0\n",
    "    planet.porb = b_per\n",
    "    planet.inc = b_inc\n",
    "    planet.r = b_r\n",
    "    planet.a = b_a\n",
    "    \n",
    "    # Stellar brightness-weighted velocity profile\n",
    "    star.reset()\n",
    "    star[:3, :] = get_ylm_coeffs(veq=veq, inc=inc, obl=obl, alpha=np.abs(alpha))\n",
    "    star[0, 0] = 1\n",
    "    sqrtq1 = np.sqrt(q1)\n",
    "    u1 = 2 * sqrtq1 * q2\n",
    "    u2 = sqrtq1 * (1 - 2 * q2)\n",
    "    star[1] = u1\n",
    "    star[2] = u2\n",
    "    \n",
    "    # Compute the integral of the brightness-weighted velocity field.\n",
    "    # As we explain in `DifferentialRotationWithSphericalHarmonics.ipynb`,\n",
    "    # what we're actually computing here is the integral of (Iv + I)\n",
    "    system.compute(time)\n",
    "    intIv_plus_I = star.lightcurve\n",
    "    \n",
    "    # Compute the integral of the brightness, I; this is the\n",
    "    # RM effect normalization.\n",
    "    map_unif[0, 0] = 1\n",
    "    map_unif[1] = u1\n",
    "    map_unif[2] = u2\n",
    "    intI = map_unif.flux(xo=planet.X, yo=planet.Y, ro=planet.r)\n",
    "\n",
    "    # The RM effect is the integral of Iv divided by the integral of I\n",
    "    # Note that we must subtract out the I term from the numerator\n",
    "    model = (intIv_plus_I - intI) / intI\n",
    "    \n",
    "    # Add a baseline\n",
    "    model += baseline - K * np.sin(2 * np.pi / b_per * (time - b_t0))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike(x):\n",
    "    \"\"\"Return the prior times the log-likelihood for a parameter vector `x`.\"\"\"\n",
    "    # Evaluate the prior\n",
    "    lp = prior.evaluate(x)\n",
    "    if np.isinf(lp):\n",
    "        return lp\n",
    "    \n",
    "    # Compute the model\n",
    "    model = compute(x)\n",
    "    \n",
    "    # Compute the likelihood from chi-squared\n",
    "    ln_err = x[-1]\n",
    "    N = len(time)\n",
    "    return lp - 0.5 * np.sum(((model - rv) / np.exp(ln_err)) ** 2) - N * ln_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from the initial conditions a few times\n",
    "... to verify we're off to a good start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "plt.plot(time - tref, rv, '.')\n",
    "plt.xlabel(\"Time [BJD - %d]\" % tref, fontsize=16)\n",
    "plt.ylabel(\"RV [m / s]\", fontsize=16);\n",
    "\n",
    "for i in range(100):\n",
    "    model = compute(prior.guess())\n",
    "    plt.plot(time - tref, model, 'C1', alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain params\n",
    "nsteps = 150000\n",
    "nwalk = 100\n",
    "ndim = 14\n",
    "thin = 10\n",
    "nburn = int(nsteps / 5)\n",
    "\n",
    "# Run the chain, or load from disk?\n",
    "RUN_CHAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the sampler\n",
    "sampler = emcee.EnsembleSampler(nwalk, ndim, lnlike, threads=8)\n",
    "\n",
    "if RUN_CHAIN:\n",
    "    # Initial guesses\n",
    "    p0 = [prior.guess() for k in range(nwalk)]\n",
    "    # Run our MCMC chain\n",
    "    for i in tqdm(sampler.sample(p0, iterations=nsteps * thin, thin=thin), total=nsteps * thin):\n",
    "        pass\n",
    "    np.savez(\"hd189_rm.npz\", chain=sampler.chain, \n",
    "             lnprobability=sampler.lnprobability, iterations=sampler.iterations,\n",
    "             naccepted=sampler.naccepted)\n",
    "else:\n",
    "    # Load the data\n",
    "    data = np.load(\"hd189_rm.npz\")\n",
    "    sampler._chain = data['chain']\n",
    "    sampler._lnprob = data['lnprobability']\n",
    "    sampler.iterations = int(data['iterations'])\n",
    "    sampler.naccepted = data['naccepted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform some of the params\n",
    "ndim = sampler.dim\n",
    "labels = list(prior.names)\n",
    "chain = np.array(sampler.chain)\n",
    "lnprobability = np.array(sampler.lnprobability)\n",
    "\n",
    "# Take the absolute value of alpha\n",
    "chain[:, :, 3] = np.abs(chain[:, :, 3])\n",
    "\n",
    "# Subtract the reference time from t0\n",
    "chain[:, :, 8] -= tref\n",
    "prior.b_t0.mean -= tref\n",
    "\n",
    "# Compute the total 3D obliquity as in Cegla et al.\n",
    "inc = chain[:, :, 2]\n",
    "obl = chain[:, :, 1]\n",
    "b_inc = chain[:, :, 10]\n",
    "obl3d = np.arccos(np.sin(inc * np.pi / 180) * \n",
    "                  np.cos(obl * np.pi / 180) * \n",
    "                  np.sin(b_inc * np.pi / 180) + \n",
    "                  np.cos(inc * np.pi / 180) * \n",
    "                  np.cos(b_inc * np.pi / 180)).reshape(nwalk, nsteps, 1)\n",
    "obl3d *= 180 / np.pi\n",
    "\n",
    "# Compute u1 and u2\n",
    "q1 = chain[:, :, 4]\n",
    "q2 = chain[:, :, 5]\n",
    "sqrtq1 = np.sqrt(q1)\n",
    "u1 = (2 * sqrtq1 * q2).reshape(nwalk, nsteps, 1)\n",
    "u2 = (sqrtq1 * (1 - 2 * q2)).reshape(nwalk, nsteps, 1)\n",
    "chain = np.concatenate((chain, obl3d, u1, u2), axis=-1)\n",
    "ndim += 3\n",
    "labels += [r\"$\\psi$\", r\"$u_1$\", r\"$u_2$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the chains\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig.subplots_adjust(bottom=0.05, top=0.95, hspace=0.1)\n",
    "axc =  [plt.subplot2grid((9, 23), (n, 0), colspan=8, rowspan=1) for n in range(9)]\n",
    "axc += [plt.subplot2grid((9, 23), (n, 13), colspan=8, rowspan=1) for n in range(9)]\n",
    "axh =  [plt.subplot2grid((9, 23), (n, 8), colspan=2, rowspan=1, sharey=axc[n]) for n in range(9)]\n",
    "axh += [plt.subplot2grid((9, 23), (n, 21), colspan=2, rowspan=1, sharey=axc[9 + n]) for n in range(9)]\n",
    "alpha = 0.3\n",
    "\n",
    "# Thin them a little\n",
    "plot_thin = 100\n",
    "burn_idx = np.arange(0, nburn, plot_thin)\n",
    "prod_idx = np.arange(nburn, nsteps, plot_thin)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    # Plot the production part of the chains and fix the axis limits\n",
    "    for k in range(nwalk):\n",
    "        axc[i].plot(prod_idx, chain[k, nburn:, i][::plot_thin], alpha=alpha, lw=1)\n",
    "        axc[i].set_ylabel(label, fontsize=18)\n",
    "    axc[i].set_ylim(*axc[i].get_ylim())\n",
    "    axc[i].set_xticklabels([])\n",
    "    # Go back and plot the burn-in part\n",
    "    axc[i].set_prop_cycle(None)\n",
    "    for k in range(nwalk):\n",
    "        axc[i].plot(burn_idx, chain[k, :nburn, i][::plot_thin], alpha=alpha, lw=1)\n",
    "    axc[i].margins(0, None)\n",
    "    axc[i].axvline(nburn, color=\"r\", lw=1)\n",
    "    # Plot the histogram for the production part\n",
    "    axh[i].hist(chain[:, nburn:, i].flatten(), bins=30,\n",
    "                orientation=\"horizontal\", histtype='step',\n",
    "                fill=False, color='k', lw=1)\n",
    "    plt.setp(axh[i].get_yticklabels(), visible=False)\n",
    "    plt.setp(axh[i].get_xticklabels(), visible=False)\n",
    "    \n",
    "# Plot the likelihood\n",
    "for k in range(nwalk):\n",
    "    axc[-1].plot(prod_idx, lnprobability[k, nburn:][::plot_thin], alpha=alpha, lw=1)\n",
    "    axc[-1].set_ylabel(r\"$\\ln P$\", fontsize=18)\n",
    "axc[-1].set_ylim(*axc[-1].get_ylim())\n",
    "axc[-1].set_prop_cycle(None)\n",
    "for k in range(nwalk):\n",
    "    axc[-1].plot(burn_idx, lnprobability[k, :nburn][::plot_thin], alpha=alpha, lw=1)\n",
    "axc[-1].margins(0, None)\n",
    "axc[-1].axvline(nburn, color=\"r\", lw=1)\n",
    "axc[-1].set_xticklabels([])\n",
    "axh[-1].axis('off')\n",
    "plt.setp(axh[-1].get_yticklabels(), visible=False)\n",
    "plt.setp(axh[-1].get_xticklabels(), visible=False);\n",
    "\n",
    "for ax in axc:\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(6) \n",
    "fig.align_ylabels(axc[:9]);\n",
    "fig.align_ylabels(axc[9:]);\n",
    "\n",
    "# Save!\n",
    "fig.savefig(\"hd189_chains.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trefprime = tref + 62\n",
    "rv_offset = np.median(rv)\n",
    "COLOR3 = '#ff7f0e'\n",
    "\n",
    "# Plot the data + model\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True, gridspec_kw = {'height_ratios':[2, 1]})\n",
    "ax[0].errorbar(time - trefprime, rv - rv_offset, err, ms=5, fmt='o', color='k', zorder=10)\n",
    "ax[0].set_ylabel(r\"RV (m s$^{-1}$)\", fontsize=16)\n",
    "\n",
    "# Plot 500 random samples\n",
    "for i in range(500):\n",
    "    idx = np.random.randint(0, nwalk * nsteps)\n",
    "    model = compute(sampler.flatchain[idx])\n",
    "    ax[0].plot(time - trefprime, model - rv_offset, color=COLOR3, alpha=0.05, lw=1)\n",
    "\n",
    "\n",
    "# Plot the max like model\n",
    "idx = np.argmax(sampler.flatlnprobability)\n",
    "model = compute(sampler.flatchain[idx])\n",
    "ax[0].plot(time - trefprime, model - rv_offset, color='k', lw=1, label=\"MAP\");\n",
    "\n",
    "# Hack a legend\n",
    "'''\n",
    "ax[0].set_xlim(*ax[0].get_xlim())\n",
    "ax[0].set_ylim(*ax[0].get_ylim())\n",
    "ax[0].plot([0, 0], [0, 0], color=COLOR3, alpha=1, lw=1, label=\"500 random samples\")\n",
    "ax[0].legend(fontsize=12)\n",
    "'''\n",
    "\n",
    "# Plot the residuals\n",
    "#ax[1].plot(time - trefprime, rv - model, 'k.');\n",
    "#ax[1].plot(time - trefprime, rv - model, 'k-', color='k', lw=1);\n",
    "ax[1].errorbar(time - trefprime, rv - model, err, fmt='o', ms=5, color='k')\n",
    "ax[1].axhline(0, color='k', ls='--', alpha=0.5);\n",
    "ax[1].set_xlabel(\"Time (BJD - %d)\" % trefprime, fontsize=16, labelpad=20)\n",
    "ax[1].set_ylabel(r\"Residuals (m s$^{-1}$)\", fontsize=16);\n",
    "fig.align_ylabels()\n",
    "\n",
    "for axis in ax:\n",
    "    for tick in axis.xaxis.get_major_ticks() + axis.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(14)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=.05)\n",
    "# Save!\n",
    "fig.savefig(\"hd189_samples.pdf\")\n",
    "fig.savefig(\"../paper/figures/hd189_rm.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the corner plot for all params\n",
    "samples = chain[:, nburn:, :].reshape(nwalk * (nsteps - nburn), ndim)\n",
    "\n",
    "# Thin them a tiny bit\n",
    "corner_thin = 10\n",
    "samples = samples[::corner_thin]\n",
    "\n",
    "# Plot\n",
    "fig = corner.corner(samples, labels=labels, bins=50, plot_datapoints=False);\n",
    "\n",
    "# Plot the priors\n",
    "for ind in range(ndim):\n",
    "    if ind < len(prior.params):\n",
    "        x = np.array([getattr(prior, prior.params[ind]).sample() \n",
    "                      for i in range(len(samples))])\n",
    "        ax = fig.axes[(ndim + 1) * ind]\n",
    "        n, _, _ = ax.hist(x, bins=50, weights=None,\n",
    "                          range=np.sort([x.min(), x.max()]),\n",
    "                          histtype=\"step\", color=\"C0\")\n",
    "            \n",
    "for ax in fig.axes:\n",
    "    ax.xaxis.label.set_fontsize(20)\n",
    "    ax.yaxis.label.set_fontsize(20)\n",
    "\n",
    "# Save!\n",
    "fig.savefig(\"hd189_corner.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce Figure 4 in Cegla et al.\n",
    "inds = [3, 0, 2, 1, 14]\n",
    "samples_cegla = np.array([samples[:, inds[0]],\n",
    "                          samples[:, inds[1]],\n",
    "                          samples[:, inds[2]],\n",
    "                          samples[:, inds[3]],\n",
    "                          samples[:, inds[4]]]).T\n",
    "labels_cegla = [labels[i] for i in inds]\n",
    "\n",
    "# Corner plot\n",
    "fig = corner.corner(samples_cegla, labels=labels_cegla, bins=50, plot_datapoints=False);\n",
    "    \n",
    "for ax in fig.axes:\n",
    "    ax.xaxis.label.set_fontsize(20)\n",
    "    ax.yaxis.label.set_fontsize(20)\n",
    "    \n",
    "# Save!\n",
    "fig.savefig(\"hd189_corner_cegla.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
